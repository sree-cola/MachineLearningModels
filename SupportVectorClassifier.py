# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1483Tr2aow92bh20Pe2T5vd3pcODeNry5
"""

#SVM- Support Vector Machine-SVC(Support Vector Classifier)

s=['Congrats,You have won lottery and if you want lottery money,call the lottery numberand get your money',
   'Give your bank details for lottery money',
   'Lottery for sure if bank details verified']
s

type(s)

#tokeization - Aplitting up data into differnt values called tokens
s[1].split()

#1.COUNTVECTORIZER()-says (how relevant a word is to a sentence/ddocument)
from sklearn.feature_extraction.text import CountVectorizer
vect=CountVectorizer(stop_words='english')
op=vect.fit_transform(s).toarray()
#stopwords -are english words which donot add extreme meaning to the sentence
#the transformation is done in such a way that the meaning of the sentence is not sacrificed

op

import pandas as pd
df=pd.DataFrame(op,columns = vect.get_feature_names())
df

#2Tf-IDF VECTORIZER
#TF-Term frequncy,IDF-Inverse Document Frequency
from sklearn.feature_extraction.text import TfidfVectorizer
vect=TfidfVectorizer(stop_words='english')
op=vect.fit_transform(s).toarray()

import pandas as pd
df=pd.DataFrame(op,columns =vect.get_feature_names())
df

#SVC MODEL
#dataset-Spamham dataset

import pandas as pd
df=pd.read_csv('https://raw.githubusercontent.com/diazoniclabs/Machine-Learning-using-sklearn/master/Datasets/spam.tsv',sep='\t')
df

df.info()

df['label'].value_counts()

#divide the data into input and output
#input-message
#output-label

x=df.iloc[:,1].values #only when text messages are involved input is 1Dd
y=df.iloc[:,0].values
print(x)
print(y)

#3Train test and split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(x,y,random_state=0)

#Apply Tfidf/Count Vectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
vect=TfidfVectorizer()
x_train_v=vect.fit_transform(x_train)#transformed data
x_test_v=vect.transform(x_test)#transformed data

#Apply a Classifier/Regresor/Clusterer
from sklearn.svm import  SVC
model =SVC()

#model fitting
model.fit(x_train_v,y_train)

#predict the ouput
y_pred=model.predict(x_test_v)
y_pred

y_test

from sklearn.metrics import accuracy_score
accuracy_score(y_pred,y_test)*100

#Evaluating a specific message
a=df['message'][10]
a

a=vect.transform([a])
model.predict(a)

b="win free tickets"
b

b=vect.transform([b])
model.predict(b)

#List of event
#W1.Gather data and create Dataframe
#2.Divided the data into i/p and o/p
#3.train_test_split
#4.Apply TfidVectorizer
#5.Apply SVC
#6.Predicted the ouput

#For Deployment we have to combine TfidfVectorizer and SVC together
#To combine modules, we using a technique called as pipelining

#pipline in sklearn -JOIN two or more modules

from sklearn.pipeline import make_pipeline
text_model=make_pipeline(TfidfVectorizer(),SVC())

#FIT MY The pipeling model
text_model.fit(x_train,y_train)

#predic the ouput
y_pred1=text_model.predict(x_test)
y_pred1

#to check the accuracy of piplelined model
accuracy_score(y_pred1,y_test)*100

#evaluate a specific message
a1=df['message'][2]
a1

a1= vect.transform([a1])
model.predict(a1)

#joblib-1.dumo 2.load
import joblib
joblib.dump(text_model,'spam-ham')

